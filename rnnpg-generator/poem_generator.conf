
topK = 20  # topK sentences will be printed to the output file
model = ../MISC/200_0.006250.model   # the path of RNNPG model
transTable12 = ../MISC/trans_table.12.4cpp   # the path for translation table
transTable23 = ../MISC/trans_table.23.4cpp   # the path for translation table
transTable34 = ../MISC/trans_table.34.4cpp   # the path for translation table
stackSize = 300   # stack size during decoding
channelOption = 1   # 1 for inverted translation feature and inverted lexical translation feature
weightFile12-5 = ../MISC/SDecoder_cfg.txt.ZMERT.final.12-5       # trained feature weight
weightFile12-7 = ../MISC/SDecoder_cfg.txt.ZMERT.final.12-7       # trained feature weight
weightFile23-5 = ../MISC/SDecoder_cfg.txt.ZMERT.final.23-5       # trained feature weight
weightFile23-7 = ../MISC/SDecoder_cfg.txt.ZMERT.final.23-7       # trained feature weight
weightFile34-5 = ../MISC/SDecoder_cfg.txt.ZMERT.final.34-5       # trained feature weight
weightFile34-7 = ../MISC/SDecoder_cfg.txt.ZMERT.final.34-7       # trained feature weight
ngramLM = ../MISC/kenlm.poem.20140306.bin        # path for ngram model
ngramFeatOn = 1     # using ngram feature
pingshuiyunDir = ../MISC/psy_table_cpp   # path for Pingshuiyun Table
